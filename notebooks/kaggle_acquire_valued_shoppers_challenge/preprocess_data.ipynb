{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "s2VGz60wbOiq"
   },
   "outputs": [],
   "source": [
    "#@title Copyright 2019 The Lifetime Value Authors.\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ============================================================================"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBoqlan65Q9T"
   },
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/google/lifetime_value/blob/master/notebooks/kaggle_acquire_valued_shoppers_challenge/preprocess_data.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://github.com/google/lifetime_value/blob/master/notebooks/kaggle_acquire_valued_shoppers_challenge/preprocess_data.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KObdQwyXH2mC"
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "K41RmAfNXtu_"
   },
   "outputs": [],
   "source": [
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DoN-PRvNuIti"
   },
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "3GGpDbxd3S5L"
   },
   "outputs": [],
   "source": [
    "COMPANYS = [\n",
    "    '10000', '101200010', '101410010', '101600010', '102100020', '102700020',\n",
    "    '102840020', '103000030', '103338333', '103400030', '103600030',\n",
    "    '103700030', '103800030', '104300040', '104400040', '104470040',\n",
    "    '104900040', '105100050', '105150050', '107800070'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = './tmp/acquire-valued-shoppers-challenge' # @param { isTemplate: true, type: 'string'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzTaK6fFXMWT"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFi0JMPu138h"
   },
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "krXMbrkVNtdN"
   },
   "source": [
    "Setup kaggle API correctly following https://www.kaggle.com/docs/api\n",
    "```\n",
    "%%shell\n",
    "mkdir ~/.kaggle\n",
    "echo \\{\\\"username\\\":\\\"{your kaggle username}\\\",\\\"key\\\":\\\"{your kaggle api key}\\\"\\} > ~/.kaggle/kaggle.json\n",
    "pip install kaggle\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: DATA_FOLDER=./tmp/acquire-valued-shoppers-challenge\n"
     ]
    }
   ],
   "source": [
    "# Set it DATA_FOLDER as an environment variable\n",
    "%env DATA_FOLDER=$DATA_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "0gf4ipd-14x0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, no need to download.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "if [ -e $DATA_FOLDER/transactions.csv ]\n",
    "then\n",
    "  echo \"File already exists, no need to download.\"\n",
    "else\n",
    "  rm -rf $DATA_FOLDER\n",
    "  mkdir -p $DATA_FOLDER\n",
    "  cd $DATA_FOLDER\n",
    "  kaggle competitions download -c acquire-valued-shoppers-challenge\n",
    "  echo \"Unzip file. This may take 10 min.\"\n",
    "  unzip acquire-valued-shoppers-challenge.zip transactions.csv.gz\n",
    "  gunzip transactions.csv.gz\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IT53azGsa2a2"
   },
   "source": [
    "### Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5tIMvE3dW1Ky"
   },
   "outputs": [],
   "source": [
    "def load_data(company):\n",
    "  all_data_filename = f'{DATA_FOLDER}/transactions.csv'\n",
    "  one_company_data_filename = f'{DATA_FOLDER}/transactions_company_{company}.csv'\n",
    "  if os.path.isfile(one_company_data_filename):\n",
    "    df = pd.read_csv(one_company_data_filename)\n",
    "  else:\n",
    "    data_list = []\n",
    "    chunksize = 10**6\n",
    "    # 350 iterations\n",
    "    for chunk in tqdm.tqdm(pd.read_csv(all_data_filename, chunksize=chunksize)):\n",
    "      data_list.append(chunk.query(\"company=='{}'\".format(company)))\n",
    "    df = pd.concat(data_list, axis=0)\n",
    "    df.to_csv(one_company_data_filename, index=None)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ra4bfwCVwKn"
   },
   "source": [
    "### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "PlJl5g9Delmi"
   },
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "  df = df.query('purchaseamount>0')\n",
    "  df['date'] = pd.to_datetime(df['date'], format='%Y-%m-%d')\n",
    "  df['start_date'] = df.groupby('id')['date'].transform('min')\n",
    "\n",
    "  # Compute calibration values\n",
    "  calibration_value = (\n",
    "      df.query('date==start_date').groupby('id')\n",
    "      ['purchaseamount'].sum().reset_index())\n",
    "  calibration_value.columns = ['id', 'calibration_value']\n",
    "\n",
    "  # Compute holdout values\n",
    "  one_year_holdout_window_mask = (\n",
    "      (df['date'] > df['start_date']) &\n",
    "      (df['date'] <= df['start_date'] + np.timedelta64(365, 'D')))\n",
    "  holdout_value = (\n",
    "      df[one_year_holdout_window_mask].groupby('id')\n",
    "      ['purchaseamount'].sum().reset_index())\n",
    "  holdout_value.columns = ['id', 'holdout_value']\n",
    "\n",
    "  # Compute calibration attributes\n",
    "  calibration_attributes = (\n",
    "      df.query('date==start_date').sort_values(\n",
    "          'purchaseamount', ascending=False).groupby('id')[[\n",
    "              'chain', 'dept', 'category', 'brand', 'productmeasure'\n",
    "          ]].first().reset_index())\n",
    "\n",
    "  # Merge dataframes\n",
    "  customer_level_data = (\n",
    "      calibration_value.merge(calibration_attributes, how='left',\n",
    "                              on='id').merge(\n",
    "                                  holdout_value, how='left', on='id'))\n",
    "  customer_level_data['holdout_value'] = (\n",
    "      customer_level_data['holdout_value'].fillna(0.))\n",
    "  categorical_features = ([\n",
    "      'chain', 'dept', 'category', 'brand', 'productmeasure'\n",
    "  ])\n",
    "  customer_level_data[categorical_features] = (\n",
    "      customer_level_data[categorical_features].fillna('UNKNOWN'))\n",
    "\n",
    "  # Specify data types\n",
    "  customer_level_data['log_calibration_value'] = (\n",
    "      np.log(customer_level_data['calibration_value']).astype('float32'))\n",
    "  customer_level_data['chain'] = (\n",
    "      customer_level_data['chain'].astype('category'))\n",
    "  customer_level_data['dept'] = (customer_level_data['dept'].astype('category'))\n",
    "  customer_level_data['brand'] = (\n",
    "      customer_level_data['brand'].astype('category'))\n",
    "  customer_level_data['category'] = (\n",
    "      customer_level_data['category'].astype('category'))\n",
    "  customer_level_data['label'] = (\n",
    "      customer_level_data['holdout_value'].astype('float32'))\n",
    "  return customer_level_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Bx80J6Ztferj"
   },
   "outputs": [],
   "source": [
    "def process(company):\n",
    "  print(\"Process company {}\".format(company))\n",
    "  transaction_level_data = load_data(company)\n",
    "  customer_level_data = preprocess(transaction_level_data)\n",
    "  customer_level_data_file = f\"{DATA_FOLDER}/customer_level_data_company_{company}.csv\"\n",
    "  customer_level_data.to_csv(customer_level_data_file, index=None)\n",
    "  print(\"Done company {}\".format(company))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q05sKVnxi8mV"
   },
   "source": [
    "This step may take a while to finish -- 10min-1hr depending on number of core in\n",
    "the computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "88dVPdt5QWpu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process company 101410010Process company 101200010Process company 101600010Process company 102700020Process company 102100020Process company 103338333Process company 10000Process company 103000030Process company 103400030Process company 103600030\n",
      "\n",
      "\n",
      "Process company 104300040\n",
      "\n",
      "\n",
      "Process company 102840020Process company 103800030Process company 104900040Process company 105100050\n",
      "Process company 104470040Process company 105150050\n",
      "Process company 103700030Process company 107800070\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Process company 104400040\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [05:30,  1.06it/s]\n",
      "333it [05:30,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 101200010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [05:40,  1.03it/s]\n",
      "342it [05:40,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 102700020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [05:43,  1.02it/s]\n",
      "339it [05:43,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 104400040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [05:43,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 103400030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [05:45,  1.01it/s]\n",
      "341it [05:45,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 103800030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [05:46,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 103338333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [05:47,  1.01it/s]\n",
      "332it [05:47,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 105150050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [05:48,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 101600010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [05:49,  1.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 105100050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [05:51,  1.00s/it]\n",
      "340it [05:51,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 104470040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [05:52,  1.01s/it]\n",
      "347it [05:52,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 102100020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [05:54,  1.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 102840020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [05:55,  1.02s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 107800070\n",
      "Done company 10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [05:58,  1.02s/it]\n",
      "347it [05:58,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 103000030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [05:59,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 104300040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [06:00,  1.03s/it]\n",
      "346it [06:00,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 103700030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [06:01,  1.03s/it]\n",
      "348it [06:01,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 101410010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "350it [06:03,  1.04s/it]\n",
      "350it [06:03,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done company 104900040\n",
      "Done company 103600030\n"
     ]
    }
   ],
   "source": [
    "p = multiprocessing.Pool(multiprocessing.cpu_count())\n",
    "_ = p.map(process, COMPANYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "last_runtime": {
    "build_target": "",
    "kind": "local"
   },
   "name": "preprocess_data.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
